{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Starbucks Idea Social-Network Analysis\n",
    "-------------------------------------\n",
    "pip install pandas sqlalchemy pymysql networkx python-louvain scikit-learn\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import networkx as nx\n",
    "import community as community_louvain            # pip install python-louvain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 0  Database connection\n",
    "# ───────────────────────────────────────────────\n",
    "password = quote_plus(\"RoronovaZoro@3\")           # escape special chars\n",
    "ENGINE = create_engine(\n",
    "    f\"mysql+pymysql://root:{password}@localhost:3306/set_local\",\n",
    "    echo=False,\n",
    "    pool_recycle=3600,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 116,673 suggestions  |  237,925 comments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/2px0j93s1m5dfxvjqvtkp4tc0000gn/T/ipykernel_87117/121978169.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_suggestion[\"timestamp\"] = pd.to_datetime(df_suggestion[\"timestamp\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 1  Load data\n",
    "# ───────────────────────────────────────────────\n",
    "df_suggestion = pd.read_sql(\"SELECT * FROM sbf_suggestion\", ENGINE)\n",
    "df_comment    = pd.read_sql(\"SELECT * FROM sbf_comment\",    ENGINE)\n",
    "\n",
    "print(f\"Loaded {len(df_suggestion):,} suggestions  |  {len(df_comment):,} comments\")\n",
    "\n",
    "# unify timestamp dtype\n",
    "df_suggestion[\"timestamp\"] = pd.to_datetime(df_suggestion[\"timestamp\"], errors=\"coerce\")\n",
    "df_comment[\"timestamp\"]    = pd.to_datetime(df_comment[\"timestamp\"],    errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 2  Helper joins\n",
    "# ───────────────────────────────────────────────\n",
    "def aggregated_join():\n",
    "    metrics = (\n",
    "        df_comment.groupby(\"suggestionId\")\n",
    "        .agg(\n",
    "            comment_count            = (\"commentId\", \"count\"),\n",
    "            unique_commenters        = (\"author\",    \"nunique\"),\n",
    "            first_comment_time       = (\"timestamp\", \"min\"),\n",
    "            last_comment_time        = (\"timestamp\", \"max\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    j = df_suggestion.merge(metrics, on=\"suggestionId\", how=\"left\")\n",
    "    j[\"comment_count\"]      = j[\"comment_count\"].fillna(0).astype(int)\n",
    "    j[\"unique_commenters\"]  = j[\"unique_commenters\"].fillna(0).astype(int)\n",
    "    j[\"lifetime_days\"]      = (j[\"last_comment_time\"] - j[\"timestamp\"]).dt.days\n",
    "    j.loc[j[\"comment_count\"]==0, \"lifetime_days\"] = 0\n",
    "    j.loc[j[\"lifetime_days\"] < 1, \"lifetime_days\"] = 1   # min 1 day if comments exist\n",
    "    j[\"lifetime_days\"]      = j[\"lifetime_days\"].fillna(0).astype(int)\n",
    "    return j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_engagement(hours=24):\n",
    "    base_time = df_suggestion.set_index(\"suggestionId\")[\"timestamp\"]\n",
    "    c = df_comment.copy()\n",
    "    c[\"suggestion_time\"] = c[\"suggestionId\"].map(base_time)\n",
    "    c[\"hours_since\"]     = (c[\"timestamp\"] - c[\"suggestion_time\"]).dt.total_seconds() / 3600\n",
    "    early                = c[c[\"hours_since\"] <= hours]\n",
    "\n",
    "    metrics = (\n",
    "        early.groupby(\"suggestionId\")\n",
    "        .agg(\n",
    "            early_comment_count       = (\"commentId\", \"count\"),\n",
    "            early_unique_commenters   = (\"author\",    \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    j = df_suggestion.merge(metrics, on=\"suggestionId\", how=\"left\")\n",
    "    j[\"early_comment_count\"]      = j[\"early_comment_count\"].fillna(0).astype(int)\n",
    "    j[\"early_unique_commenters\"]  = j[\"early_unique_commenters\"].fillna(0).astype(int)\n",
    "    return j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_activity_join():\n",
    "    sugg = (\n",
    "        df_suggestion.groupby(\"author\")\n",
    "        .agg(\n",
    "            suggestion_count = (\"suggestionId\", \"count\"),\n",
    "            total_votes      = (\"votes\",        \"sum\"),\n",
    "            avg_votes        = (\"votes\",        \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    comm = (\n",
    "        df_comment.groupby(\"author\")\n",
    "        .agg(\n",
    "            comment_count                = (\"commentId\", \"count\"),\n",
    "            unique_suggestions_commented = (\"suggestionId\", \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    u = sugg.merge(comm, on=\"author\", how=\"outer\").fillna(0)\n",
    "    u[\"total_activity\"] = u[\"suggestion_count\"] + u[\"comment_count\"]\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def network_connections_join():\n",
    "    sugg_auth = df_suggestion[[\"suggestionId\", \"author\"]].rename(columns={\"author\":\"suggestion_author\"})\n",
    "    conn = df_comment.merge(sugg_auth, on=\"suggestionId\", how=\"inner\")\n",
    "    conn = conn[conn[\"author\"] != conn[\"suggestion_author\"]]     # drop self-comments\n",
    "    edges = (\n",
    "        conn.groupby([\"author\",\"suggestion_author\"])\n",
    "        .agg(interaction_count=(\"commentId\",\"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data-set shapes:\n",
      "  Aggregated        : (116673, 13)\n",
      "  Early engagement  : (116673, 10)\n",
      "  User activity     : (126447, 7)\n",
      "  User interactions : (157211, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build tables\n",
    "agg_df     = aggregated_join()\n",
    "time_df    = time_based_engagement()\n",
    "user_df    = user_activity_join()\n",
    "network_df = network_connections_join()\n",
    "\n",
    "print(\"\\nData-set shapes:\")\n",
    "print(\"  Aggregated        :\", agg_df.shape)\n",
    "print(\"  Early engagement  :\", time_df.shape)\n",
    "print(\"  User activity     :\", user_df.shape)\n",
    "print(\"  User interactions :\", network_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 3  Assign user roles (simple quantile heuristic)\n",
    "# ───────────────────────────────────────────────\n",
    "q70, q90 = user_df[\"total_activity\"].quantile([0.7, 0.9])\n",
    "def role_from_activity(a):\n",
    "    if a > q90:  return \"expert\"\n",
    "    if a > q70:  return \"regular\"\n",
    "    return \"casual\"\n",
    "\n",
    "user_df[\"role\"] = user_df[\"total_activity\"].apply(role_from_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected 4902 communities in the user-interaction graph\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 4  Build interaction network & communities\n",
    "# ───────────────────────────────────────────────\n",
    "G = nx.DiGraph()\n",
    "for _, row in network_df.iterrows():\n",
    "    G.add_edge(row[\"author\"], row[\"suggestion_author\"], weight=row[\"interaction_count\"])\n",
    "\n",
    "# community detection on undirected projection\n",
    "partition = community_louvain.best_partition(G.to_undirected(), weight=\"weight\")\n",
    "nx.set_node_attributes(G, partition, \"community\")\n",
    "\n",
    "# add centrality measures\n",
    "nx.set_node_attributes(G, nx.pagerank(G, weight=\"weight\"),         \"pagerank\")\n",
    "nx.set_node_attributes(G, nx.degree_centrality(G),                 \"deg_centrality\")\n",
    "\n",
    "print(f\"\\nDetected {len(set(partition.values()))} communities in the user-interaction graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph successfully exported to interaction_network.gexf\n"
     ]
    }
   ],
   "source": [
    "output_filename = \"interaction_network.gexf\"\n",
    "nx.write_gexf(G, output_filename)\n",
    "\n",
    "print(f\"\\nGraph successfully exported to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────\n",
    "# 5  Prepare data for idea-success modelling\n",
    "# ───────────────────────────────────────────────\n",
    "model_df = (\n",
    "    agg_df\n",
    "    .merge(time_df[[\"suggestionId\",\"early_comment_count\",\"early_unique_commenters\"]],\n",
    "           on=\"suggestionId\")\n",
    "    .copy()\n",
    ")\n",
    "model_df[\"success\"] = (model_df[\"votes\"] >= 10).astype(int)        # tweak threshold freely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"comment_count\",\"unique_commenters\",\n",
    "    \"early_comment_count\",\"early_unique_commenters\",\n",
    "    \"lifetime_days\"\n",
    "]\n",
    "X = model_df[features]\n",
    "y = model_df[\"success\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek/Documents/sb_ideaforce/venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/abhishek/Documents/sb_ideaforce/venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/abhishek/Documents/sb_ideaforce/venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/abhishek/Documents/sb_ideaforce/venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/abhishek/Documents/sb_ideaforce/venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/abhishek/Documents/sb_ideaforce/venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic-Regression Results\n",
      "  ROC AUC : 0.631\n",
      "  Coefficients:\n",
      "    comment_count          -0.0437\n",
      "    unique_commenters      +0.4629\n",
      "    early_comment_count    +0.0572\n",
      "    early_unique_commenters -0.7418\n",
      "    lifetime_days          +0.0003\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLogistic-Regression Results\")\n",
    "print(\"  ROC AUC :\", roc_auc_score(y_test, proba).round(3))\n",
    "print(\"  Coefficients:\")\n",
    "for f, c in zip(features, clf.coef_[0]):\n",
    "    print(f\"    {f:<22} {c:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (threshold=0.5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.571     0.884     0.694     15563\n",
      "           1      0.644     0.240     0.349     13606\n",
      "\n",
      "    accuracy                          0.584     29169\n",
      "   macro avg      0.608     0.562     0.522     29169\n",
      "weighted avg      0.605     0.584     0.533     29169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional detailed classification metrics\n",
    "print(\"\\nClassification report (threshold=0.5):\\n\",\n",
    "      classification_report(y_test, (proba>=0.5).astype(int), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
