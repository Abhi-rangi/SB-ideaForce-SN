{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sug = pd.read_csv(\"top100_suggestions.csv\") \\\n",
    "        .rename(columns={\"author\": \"author_sug\"})\n",
    "com = pd.read_csv(\"top100_comments.csv\") \\\n",
    "        .rename(columns={\"author\": \"author_com\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define explicit datetime format for your timestamp columns\n",
    "date_format = \"%m/%d/%Y %I:%M %p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse timestamps, coercing malformed entries to NaT\n",
    "sug[\"timestamp\"] = pd.to_datetime(\n",
    "    sug[\"timestamp\"],\n",
    "    format=date_format,\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "com[\"timestamp\"] = pd.to_datetime(\n",
    "    com[\"timestamp\"],\n",
    "    format=date_format,\n",
    "    errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "  Suggestions: (100, 7)\n",
      "  Comments:    (3933, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop any rows missing a suggestionId, author, or valid timestamp\n",
    "sug.dropna(subset=[\"suggestionId\", \"author_sug\", \"timestamp\"], inplace=True)\n",
    "com.dropna(subset=[\"suggestionId\", \"author_com\", \"timestamp\"], inplace=True)\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"  Suggestions:\", sug.shape)  # Expect ~116673 × 8\n",
    "print(\"  Comments:   \", com.shape)  # Expect ~237925 × 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Node & Edge Construction ---\n",
    "\n",
    "# A. Directed Comment Flow (comment-author -> suggestion-author)\n",
    "merged = com[[\"suggestionId\",\"author_com\"]].merge(\n",
    "    sug[[\"suggestionId\",\"author_sug\"]],\n",
    "    on=\"suggestionId\"\n",
    ")\n",
    "edge_flow = (\n",
    "    merged\n",
    "    .groupby([\"author_com\",\"author_sug\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    "    .rename(columns={\"author_com\":\"src\",\"author_sug\":\"dst\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Undirected Co-commenter (users who commented the same suggestion)\n",
    "co_pairs = []\n",
    "for _, grp in com.groupby(\"suggestionId\")[\"author_com\"]:\n",
    "    users = set(grp)\n",
    "    for u, v in combinations(users, 2):\n",
    "        co_pairs.append((u, v))\n",
    "df_co = pd.DataFrame(co_pairs, columns=[\"u\",\"v\"])\n",
    "edge_co = (\n",
    "    df_co\n",
    "    .groupby([\"u\",\"v\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Suggestion Projection (suggestions linked by shared users)\n",
    "# Build a user–suggestion mapping from both authorship and comments\n",
    "sug_edges = pd.concat([\n",
    "    sug[[\"suggestionId\",\"author_sug\"]].rename(columns={\"author_sug\":\"user\"}),\n",
    "    com[[\"suggestionId\",\"author_com\"]].rename(columns={\"author_com\":\"user\"})\n",
    "]).drop_duplicates()\n",
    "\n",
    "proj_pairs = []\n",
    "for _, group in sug_edges.groupby(\"user\")[\"suggestionId\"]:\n",
    "    for s1, s2 in combinations(set(group), 2):\n",
    "        proj_pairs.append((s1, s2))\n",
    "df_proj = pd.DataFrame(proj_pairs, columns=[\"s1\",\"s2\"])\n",
    "edge_proj = (\n",
    "    df_proj\n",
    "    .groupby([\"s1\",\"s2\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Bipartite User–Suggestion\n",
    "bip_edges = (\n",
    "    sug_edges\n",
    "    .groupby([\"user\",\"suggestionId\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"weight\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Graph Assembly & Export to GEXF ---\n",
    "\n",
    "# 3A. Directed Comment Flow Graph\n",
    "G_flow = nx.DiGraph()\n",
    "for _, row in edge_flow.iterrows():\n",
    "    G_flow.add_edge(row.src, row.dst, weight=int(row.weight))\n",
    "nx.write_gexf(G_flow, \"./gephi_100/comment_flow.gexf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3B. Undirected Co-commenter Graph\n",
    "G_co = nx.Graph()\n",
    "for _, row in edge_co.iterrows():\n",
    "    G_co.add_edge(row.u, row.v, weight=int(row.weight))\n",
    "nx.write_gexf(G_co, \"./gephi_100/co_commenters.gexf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3C. Suggestion Projection Graph (undirected)\n",
    "G_proj = nx.Graph()\n",
    "for _, row in edge_proj.iterrows():\n",
    "    # prefix 'sug_' to avoid name collisions with user names\n",
    "    G_proj.add_edge(f\"sug_{row.s1}\", f\"sug_{row.s2}\", weight=int(row.weight))\n",
    "nx.write_gexf(G_proj, \"./gephi_100/suggestion_projection.gexf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Load the co-commenter graph ---\n",
    "G = nx.read_gexf(\"gephi_100/co_commenters.gexf\")\n",
    "\n",
    "# --- 2. Community Detection (Greedy Modularity) ---\n",
    "communities = list(greedy_modularity_communities(G, weight='weight'))\n",
    "node_to_comm = {node: cid for cid, comm in enumerate(communities) for node in comm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Community Sizes ---\n",
    "comm_sizes = pd.DataFrame({\n",
    "    'community_id': list(range(len(communities))),\n",
    "    'size': [len(comm) for comm in communities]\n",
    "})\n",
    "comm_sizes.to_csv(\"community_sizes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Inter-Community Edge Weights ---\n",
    "inter = {}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    cu, cv = node_to_comm[u], node_to_comm[v]\n",
    "    if cu != cv:\n",
    "        key = tuple(sorted((cu, cv)))\n",
    "        inter[key] = inter.get(key, 0) + data.get('weight', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inter_df = pd.DataFrame([\n",
    "    {'community_1': k[0], 'community_2': k[1], 'weight': w}\n",
    "    for k, w in inter.items()\n",
    "]).sort_values('weight', ascending=False)\n",
    "inter_df.to_csv(\"inter_community_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Identify Bridge-Nodes (Inter-Community Connectors) ---\n",
    "# Betweenness centrality\n",
    "betweenness = nx.betweenness_centrality(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of weights on edges that cross communities\n",
    "inter_edge_weight = {node: 0 for node in G.nodes()}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if node_to_comm[u] != node_to_comm[v]:\n",
    "        w = data.get('weight', 1)\n",
    "        inter_edge_weight[u] += w\n",
    "        inter_edge_weight[v] += w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to CSV:\n",
      " - community_sizes.csv\n",
      " - inter_community_weights.csv\n",
      " - bridge_nodes.csv\n"
     ]
    }
   ],
   "source": [
    "bridge_df = pd.DataFrame([\n",
    "    {\n",
    "        'node': node,\n",
    "        'community': node_to_comm[node],\n",
    "        'betweenness': betweenness[node],\n",
    "        'inter_edge_weight': inter_edge_weight[node]\n",
    "    }\n",
    "    for node in G.nodes()\n",
    "]).sort_values('inter_edge_weight', ascending=False)\n",
    "bridge_df.to_csv(\"bridge_nodes.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to CSV:\")\n",
    "print(\" - community_sizes.csv\")\n",
    "print(\" - inter_community_weights.csv\")\n",
    "print(\" - bridge_nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported co_commenters_top100_communities.gexf with community attributes.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# 1. Load your co‐commenter graph\n",
    "G = nx.read_gexf(\"gephi_100/co_commenters.gexf\")\n",
    "\n",
    "# 2. Detect communities\n",
    "communities = list(greedy_modularity_communities(G, weight='weight'))\n",
    "\n",
    "# 3. Build a mapping node → community_id\n",
    "node_to_comm = {\n",
    "    node: comm_id\n",
    "    for comm_id, comm in enumerate(communities)\n",
    "    for node in comm\n",
    "}\n",
    "\n",
    "# 4. Attach the community as a node attribute\n",
    "nx.set_node_attributes(G, node_to_comm, name=\"community\")\n",
    "\n",
    "# 5. Attach community size and total count as graph attributes\n",
    "G.graph['num_communities'] = len(communities)\n",
    "comm_sizes = {comm_id: len(comm) for comm_id, comm in enumerate(communities)}\n",
    "for node, comm_id in node_to_comm.items():\n",
    "    G.nodes[node]['community_size'] = comm_sizes[comm_id]\n",
    "\n",
    "# 6. Export to GEXF for Gephi\n",
    "nx.write_gexf(G, \"gephi_100/co_commenters_top100_communities.gexf\")\n",
    "\n",
    "print(\"Exported co_commenters_top100_communities.gexf with community attributes.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
